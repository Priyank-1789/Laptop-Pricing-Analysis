{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ae0d45-b357-4e88-99be-1cb5c98ec4cb",
   "metadata": {},
   "source": [
    "# Laptops Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296fbe0-27cf-44bd-a3a9-abbed0f5f163",
   "metadata": {},
   "source": [
    "## 1. Importing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f9f19-96b5-4110-a990-3b2ba077a743",
   "metadata": {},
   "source": [
    " - Import a dataset from a CSV file to a Pandas dataframe\n",
    " - Develop some basic insights about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf494a-1791-4e65-bde6-b6421a09f7df",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7d703d-6cb9-4dae-a083-8f43ecfe0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a03c0-1bd0-4b4d-9e39-153a04698735",
   "metadata": {},
   "source": [
    "### Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30a17c2-73d4-4fcd-8138-a8c09df9a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "filepath = \"C:/Users/Priyank/Desktop/Projects/Data Analytics/1_Laptop pricing/laptops.csv\"\n",
    "df = pd.read_csv(filepath, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "270da4bf-d390-479e-a47d-65dc450382db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1          2   3   4   5       6    7   8    9     10    11\n",
      "0  Acer   4  IPS Panel   2   1   5   35.56  1.6   8  256   1.6   978\n",
      "1  Dell   3    Full HD   1   1   3  39.624  2.0   4  256   2.2   634\n",
      "2  Dell   3    Full HD   1   1   7  39.624  2.7   8  256   2.2   946\n",
      "3  Dell   4  IPS Panel   2   1   5  33.782  1.6   8  128  1.22  1244\n",
      "4    HP   4    Full HD   2   1   7  39.624  1.8   8  256  1.91   837\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a382fc7-6324-4ec5-95cb-9e476082ea0a",
   "metadata": {},
   "source": [
    "### Add headers to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570c0de-7b68-48ec-974f-8a4175432c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Manufacturer\", \"Category\", \"Screen\", \"GPU\", \"OS\", \"CPU_core\", \"Screen_Size_cm\", \"CPU_frequency\", \"RAM_GB\", \"Storage_GB_SSD\", \"Weight_kg\", \"Price\"]\n",
    "df.columns = headers\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89023d-4be5-44a4-86b8-2a68591cf09b",
   "metadata": {},
   "source": [
    "### Replace '?' with 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a360f-a362-488e-9030-feabc57a4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?',np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8b7f3-7be7-419e-afc0-11d11ff6b809",
   "metadata": {},
   "source": [
    "<h3>Print the data types of the dataframe columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7f667-c2af-4af1-aa46-a93bf07499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the dataframe columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b384c7-28e0-42a2-ac0f-816f65a10b4e",
   "metadata": {},
   "source": [
    "<h3>Print the statistical description of the dataset, including that of 'object' data types.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341b64d-30bc-4412-8a72-531a6beb512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary information of the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8b9d8-1fb2-41c5-89d3-bdc075eb5449",
   "metadata": {},
   "source": [
    "<h3>Print the summary information of the dataset.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e82e73-6b39-4ea2-a799-fec7dfb4fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a16a3-cca5-4433-b326-cd3778708215",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling\n",
    "- Handle missing data in different ways\n",
    " - Correct the data type of different data values as per requirement\n",
    " - Standardize and normalize the appropriate data attributes\n",
    " - Visualize the data as grouped bar graph using Binning\n",
    " - Cnverting a categorical data into numerical indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed222a4b-eeb1-4c1c-b9a7-60696e129a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc79b5-c5b7-447b-aaf1-784288e3076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db4b40-fb1f-4d52-a656-0724245f9036",
   "metadata": {},
   "source": [
    "### Fixing the data types\n",
    "Both \"Weight_kg\" and \"Screen_Size_cm\" are seen to have the data type \"Object\", while both of them should be having a data type of \"float\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b305b-205a-4714-a85a-885c03a72c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column data type to float\n",
    "df['Screen_Size_cm'] = df['Screen_Size_cm'].astype(float)\n",
    "df['Weight_kg'] = df['Weight_kg'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effad894-0ae7-448d-a894-f1de3ebea24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66980f96-241c-4a33-b4d1-b2883458b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the Screen_Size_cm column such that all values are rounded to nearest 2 decimal places \n",
    "df[['Screen_Size_cm']] = np.round(df[['Screen_Size_cm']],2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94effb72-c894-4a52-838f-cdadb442261d",
   "metadata": {},
   "source": [
    "### Evaluate the dataset for missing data\n",
    "Missing data was last converted from '?' to numpy.NaN. Pandas uses NaN and Null values interchangeably. This means, you can just identify the entries having Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1645853-25c5-48be-bb18-bc794ffa3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull()\n",
    "print(missing_data.head())\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc98fd-3a35-40db-be56-ed74844212a7",
   "metadata": {},
   "source": [
    "### Replace with mean\n",
    "Missing values in attributes that have continuous data are best replaced using Mean value. We note that values in \"Weight_kg\" attribute are continuous in nature, and some values are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a99fa2-a665-4801-b5b3-996bb5ae6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing data with mean\n",
    "avg_weight = df['Weight_kg'].astype('float').mean(axis=0)\n",
    "#df[\"Weight_kg\"].replace(np.nan, avg_weight, inplace=True)    ------- not working\n",
    "df[\"Weight_kg\"] = df[\"Weight_kg\"].replace(np.nan, avg_weight)  # ----- with replace\n",
    "# df[\"Weight_kg\"] = df[\"Weight_kg\"].fillna(avg_weight)      ------- with filna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2829f-cc26-4bf3-ba5d-9492fb0c1c6d",
   "metadata": {},
   "source": [
    "### Replace with the most frequent value\n",
    "Missing values in attributes that have categorical data are best replaced using the most frequent value. We note that values in \"Screen_Size_cm\" attribute are categorical in nature, and some values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1293847-c6b0-49ae-af3f-55cedb477e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing data with mode\n",
    "\n",
    "# common_screen_size = df['Screen_Size_cm'].value_counts().idxmax()\n",
    "# df[\"Screen_Size_cm\"].replace(np.nan, common_screen_size, inplace=True) ----- not work\n",
    "\n",
    "common_screen_size = df['Screen_Size_cm'].mode()[0]  # Get the most frequent value\n",
    "df[\"Screen_Size_cm\"] = df[\"Screen_Size_cm\"].fillna(common_screen_size)   # ---- with fillna\n",
    "\n",
    "# df[\"Screen_Size_cm\"] = df[\"Screen_Size_cm\"].replace(np.nan, common_screen_size) ---- with replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eaef60-0e02-4fd0-aa71-545bf76ce5cd",
   "metadata": {},
   "source": [
    "### Data Standardization\n",
    "The value of Screen_size usually has a standard unit of inches. Similarly, weight of the laptop is needed to be in pounds. Use the below mentioned units of conversion and update their names as well.\n",
    "\n",
    "```{math}\n",
    "1 inch = 2.54 cm\n",
    "1 kg   = 2.205 pounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956627ac-00eb-403b-be70-52003b7b16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization: convert weight from kg to pounds\n",
    "df[\"Weight_kg\"] = df[\"Weight_kg\"]*2.205\n",
    "df.rename(columns={'Weight_kg':'Weight_pounds'}, inplace=True)\n",
    "\n",
    "# Data standardization: convert screen size from cm to inch\n",
    "df[\"Screen_Size_cm\"] = df[\"Screen_Size_cm\"]/2.54\n",
    "df.rename(columns={'Screen_Size_cm':'Screen_Size_inch'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66efe9e-c04c-4245-9581-9fad21bbed4a",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "Often it is required to normalize a continuous data attribute. Normalize the \"CPU_frequency\" attribute with respect to the maximum value available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d85cdf-7854-439e-b96b-cbc9afd087e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CPU_frequency'] = df['CPU_frequency']/df['CPU_frequency'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1962f6-66bc-4184-80d7-2d0629ee39b3",
   "metadata": {},
   "source": [
    "### Binning\n",
    "Binning is a process of creating a categorical attribute which splits the values of a continuous data into a specified number of groups. In this case, create 3 bins for the attribute \"Price\". These bins would be named \"Low\", \"Medium\" and \"High\". The new attribute will be named \"Price-binned\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5a23e-5c00-44cb-b946-fbf72baecba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df[\"Price\"]), max(df[\"Price\"]), 4)\n",
    "group_names = ['Low', 'Medium', 'High']\n",
    "df['Price-binned'] = pd.cut(df['Price'], bins, labels=group_names, include_lowest=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ccfa48-3c31-469f-9aa9-359f8b4efdac",
   "metadata": {},
   "source": [
    "Also, plot the bar graph of these bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca300d-15d7-4257-86d3-84a279e68cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(group_names, df[\"Price-binned\"].value_counts())\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Price bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902a005-1d59-4516-84ea-b56d49edeb79",
   "metadata": {},
   "source": [
    "### Indicator variables\n",
    "Convert the \"Screen\" attribute of the dataset into 2 indicator variables, \"Screen-IPS_panel\" and \"Screen-Full_HD\". Then drop the \"Screen\" attribute from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472877f-6792-45f9-a257-616985e795d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute\n",
    "#Indicator Variable: Screen\n",
    "dummy_variable_1 = pd.get_dummies(df[\"Screen\"])\n",
    "dummy_variable_1.rename(columns={'IPS Panel':'Screen-IPS_panel', 'Full HD':'Screen-Full_HD'}, inplace=True)\n",
    "df = pd.concat([df, dummy_variable_1], axis=1)\n",
    "\n",
    "# drop original column \"Screen\" from \"df\"\n",
    "df.drop(\"Screen\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e6cee-c7e4-48c2-9ad2-730c4b82415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6940e-e747-4149-b001-9c086ca59419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddc1ca-cd9e-4667-8974-a63032ded52a",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475293bb-85e4-4f08-a0f8-773492490e4e",
   "metadata": {},
   "source": [
    " - Visualize individual feature patterns\n",
    " - Run descriptive statistical analysis on the dataset\n",
    " - Use groups and pivot tables to find the effect of categorical variables on price\n",
    " - Use Pearson Correlation to measure the interdependence between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb251bf-d127-44a0-b097-9a15f096d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ad1b1-1124-4426-aa83-dcdae801aa05",
   "metadata": {},
   "source": [
    "### Visualize individual feature patterns\n",
    "\n",
    "#### Continuous valued features\n",
    "Generate regression plots for each of the parameters \"CPU_frequency\", \"Screen_Size_inch\" and \"Weight_pounds\" against \"Price\". Also, print the value of correlation of each feature with \"Price\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e6ae1-83bf-489c-9f77-8acea8025fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU_frequency plot\n",
    "sns.regplot(x=\"CPU_frequency\", y=\"Price\", data=df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf2f3a-1324-4ede-8815-2d8b3d503cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen_Size_inch plot\n",
    "sns.regplot(x=\"Screen_Size_inch\", y=\"Price\", data=df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e246f-fb73-4991-b7d4-29a938069716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight_pounds plot\n",
    "sns.regplot(x=\"Weight_pounds\", y=\"Price\", data=df)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66899a3-6d35-490d-b734-b84aff299749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation values of the three attributes with Price\n",
    "for param in [\"CPU_frequency\", \"Screen_Size_inch\",\"Weight_pounds\"]:\n",
    "    print(f\"Correlation of Price and {param} is \", df[[param,\"Price\"]].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9084eb-e555-45e1-838d-c655df306685",
   "metadata": {},
   "source": [
    "**Interpretation: \"CPU_frequency\" has a 36% positive correlation with the price of the laptops. The other two parameters have weak correlation with price.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fba40-22c4-497b-877b-b525ea315e17",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "Generate Box plots for the different feature that hold categorical values. These features would be \"Category\", \"GPU\", \"OS\", \"CPU_core\", \"RAM_GB\", \"Storage_GB_SSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa014b-8b32-4433-8cf9-d2448f169a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Box plot\n",
    "sns.boxplot(x=\"Category\", y=\"Price\", data=df)\n",
    "# plt.xticks(rotation=45)  # Rotate category labels for better readability\n",
    "plt.title(\"Category vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09afbc-c02d-48fd-bc3e-f07ebbb0e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Box plot\n",
    "sns.boxplot(x=\"GPU\", y=\"Price\", data=df)\n",
    "plt.title(\"GPU vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8df3d3-fc09-4fc1-a79a-c13ec8e1a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS Box plot\n",
    "sns.boxplot(x=\"OS\", y=\"Price\", data=df)\n",
    "plt.title(\"OS vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde13479-780a-410c-bed9-6d11d45d1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU_core Box plot\n",
    "sns.boxplot(x=\"CPU_core\", y=\"Price\", data=df)\n",
    "plt.title(\"CPU core vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c18b5e-ac7d-4b2b-99ae-5c0d370a5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAM_GB Box plot\n",
    "sns.boxplot(x=\"RAM_GB\", y=\"Price\", data=df)\n",
    "plt.title(\"RAM_GB vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c8fb5-b344-4247-ae96-9d0be40fc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage_GB_SSD Box plot\n",
    "sns.boxplot(x=\"Storage_GB_SSD\", y=\"Price\", data=df)\n",
    "plt.title(\"Storage_GB_SSD vs Price Box Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fb8f5-80cd-4b47-b6ea-18858cf4dffa",
   "metadata": {},
   "source": [
    "### Descriptive Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75784c95-0944-42f3-a5b3-afb943793d63",
   "metadata": {},
   "source": [
    "Generate the statistical description of all the features being used in the data set. Include \"object\" data types as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3434b2-0cfa-4f99-a8f4-806ec78f7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())\n",
    "print()\n",
    "print(df.describe(include=['object']))\n",
    "print()\n",
    "print(df.describe(include=['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad1c53-e8d0-4425-acc1-3dfb0586139f",
   "metadata": {},
   "source": [
    "### GroupBy and Pivot Tables\n",
    "\n",
    "Grouping the parameters \"GPU\", \"CPU_core\" and \"Price\" to make a pivot table and visualize this connection using the pcolor plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1eed9-439e-46c3-80c0-5a3a44834c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the group\n",
    "df_gptest = df[['GPU','CPU_core','Price']]\n",
    "grouped_test1 = df_gptest.groupby(['GPU','CPU_core'],as_index=False).mean()\n",
    "print(grouped_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf38ff2-ca9c-4721-97e2-7f4a0fa4f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Pivot table\n",
    "grouped_pivot = grouped_test1.pivot(index='GPU',columns='CPU_core')\n",
    "print(grouped_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c852076-efac-42a7-b252-092b219c5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(grouped_pivot, cmap='RdBu')\n",
    "\n",
    "#label names\n",
    "row_labels = grouped_pivot.columns.levels[1]\n",
    "col_labels = grouped_pivot.index\n",
    "\n",
    "#move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "#insert labels\n",
    "ax.set_xticklabels(row_labels, minor=False)\n",
    "ax.set_yticklabels(col_labels, minor=False)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1c07f-1a74-4728-8695-1ad6c85ba49a",
   "metadata": {},
   "source": [
    "### Pearson Correlation and p-values\n",
    "\n",
    "Use the `scipy.stats.pearsonr()` function to evaluate the Pearson Coefficient and the p-values for each parameter tested above. This will help you determine the parameters most likely to have a strong effect on the price of the laptops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b5993-5c3c-4752-a3ee-cd47037d3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute\n",
    "for param in ['RAM_GB','CPU_frequency','Storage_GB_SSD','Screen_Size_inch','Weight_pounds','CPU_core','OS','GPU','Category']:\n",
    "    pearson_coef, p_value = stats.pearsonr(df[param], df['Price'])\n",
    "    print(param)\n",
    "    print(\"The Pearson Correlation Coefficient for \",param,\" is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d6d3a-40ac-433c-9b35-f3f4d03e36bc",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Strongest Influence on Price**\n",
    "\n",
    "- RAM_GB (r = 0.549, p < 0.0001) → Moderate positive correlation, suggesting RAM significantly impacts price.\n",
    "- CPU_core (r = 0.459, p < 0.0001) → More CPU cores increase price significantly.\n",
    "- CPU_frequency (r = 0.367, p < 0.0001) → Faster CPUs slightly increase price.\n",
    "\n",
    "**Other Notable Factors**\n",
    "\n",
    "- Storage_GB_SSD (r = 0.243, p < 0.0001) → More SSD storage leads to slightly higher price.\n",
    "- GPU (r = 0.288, p < 0.0001) → Better GPUs contribute to higher prices.\n",
    "- Category (r = 0.286, p < 0.0001) → Premium categories tend to be more expensive.\n",
    "\n",
    "**No Significant Impact on Price**\n",
    "\n",
    "- Screen Size (r = -0.111, p = 0.0888) and Weight (r = -0.050, p = 0.4398) do not significantly affect price.\n",
    "- OS (r = -0.222, p = 0.00057) shows a weak negative correlation, possibly indicating some operating systems are used in cheaper models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5e2ab-78bc-45c6-8645-b40499aa77f6",
   "metadata": {},
   "source": [
    "## 4. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86702e3-af20-4b6e-a18f-b569fa169615",
   "metadata": {},
   "source": [
    " - Use Linear Regression in one variable to fit the parameters to a model\n",
    " - Use Linear Regression in multiple variables to fit the parameters to a model\n",
    " - Use Polynomial Regression in single variable tofit the parameters to a model\n",
    " - Create a pipeline for performing linear regression using multiple features in polynomial scaling\n",
    " - Evaluate the performance of different forms of regression on basis of MSE and R^2 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b5bfb-bb4e-4141-8a69-f07c0c50c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca636e48-7399-4650-aaac-e8dce4d11095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7d9f7-0949-462a-acc8-70ba6b0ce662",
   "metadata": {},
   "source": [
    "### 4.1 Single Linear Regression\n",
    "\n",
    "You have learnt that \"CPU_frequency\" is the parameter with the lowest p-value among the different features of the dataset. Create a single feature Linear Regression model that fits the pair of \"CPU_frequency\" and \"Price\" to find the model for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6399ed9-da23-4a79-af38-6191791dd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "X = df[['CPU_frequency']]\n",
    "Y = df['Price']\n",
    "\n",
    "lm.fit(X,Y)\n",
    "\n",
    "Yhat=lm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92bc85-7869-4f56-8bdd-8b3196623a7b",
   "metadata": {},
   "source": [
    "Generate the Distribution plot for the predicted values and that of the actual values. How well did the model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc577b2c-cd07-4438-b086-0f326bc5ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "ax1 = sns.distplot(df['Price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "\n",
    "# Create a distribution plot for predicted values\n",
    "sns.distplot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Proportion of laptops')\n",
    "plt.legend(['Actual Value', 'Predicted Value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c30bb-6968-433e-87b8-40eda3f5ad12",
   "metadata": {},
   "source": [
    "Evaluate the Mean Squared Error and R^2 score values for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bca572-d16e-4c9b-ba30-a87c8a10f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_slr = mean_squared_error(df['Price'], Yhat)\n",
    "r2_score_slr = lm.score(X, Y)\n",
    "print('The R-square for Linear Regression is: ', r2_score_slr)\n",
    "print('The mean square error of price and predicted value is: ', mse_slr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261ab9a-1e3c-479d-a756-f29400887a0f",
   "metadata": {},
   "source": [
    "### 4.2 - Multiple Linear Regression\n",
    "The parameters which have a low enough p-value so as to indicate strong relationship with the 'Price' value are 'CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU' and 'Category'. Use all these variables to create a Multiple Linear Regression system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e753665-84a7-4b51-b9d4-d9b85ca584bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below and press Shift+Enter to execute \n",
    "lm1 = LinearRegression()\n",
    "Z = df[['CPU_frequency','RAM_GB','Storage_GB_SSD','CPU_core','OS','GPU','Category']]\n",
    "lm1.fit(Z,Y)\n",
    "Y_hat = lm1.predict(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ef0e2-855d-435d-9ea2-dc828d1e8d7c",
   "metadata": {},
   "source": [
    "Plot the Distribution graph of the predicted values as well as the Actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c25c9-bd78-4a32-82d5-015f141cfa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(df['Price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(Y_hat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Proportion of laptops')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295a753-ac4f-4dcf-b5a8-73a704ceb79a",
   "metadata": {},
   "source": [
    "Evaluate the Mean Squared Error and R^2 score values for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf0252-fd6b-4f91-86fb-0371876708d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_mlr = mean_squared_error(Y, Y_hat)\n",
    "# r2_score_mlr = lm1.score(Y, Y_hat)\n",
    "r2_score_mlr = r2_score(Y, Y_hat)\n",
    "print('The R-square for Multiple Linear Regression is: ', r2_score_mlr)\n",
    "print('The mean square error of price and predicted value is: ', mse_mlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486b202-00c4-45f7-a495-8e727b4db65a",
   "metadata": {},
   "source": [
    "Find the R^2 score and the MSE value for this fit. Is this better or worst than the performance of Single Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee75343-99d2-44d8-9019-7510bcd8680f",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "Multiple Linear Regression performs significantly better than Single Linear Regression.\n",
    "\n",
    "It explains 50.83% of the variance in price, compared to just 13.44% for the single model.\n",
    "It reduces prediction error by a large margin (MSE drops from 284,583 to 161,680).\n",
    "Thus, Multiple Linear Regression is the preferred model for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae6a21-b82b-43c6-a6f7-ba39b59757e9",
   "metadata": {},
   "source": [
    "### 4.3 - Polynomial Regression\n",
    "Use the variable \"CPU_frequency\" to create Polynomial features. Try this for 3 different values of polynomial degrees. Remember that polynomial fits are done using `numpy.polyfit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd010b8-226c-473c-8f65-da97e3cc6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy().flatten()\n",
    "f1 = np.polyfit(X, Y, 1)\n",
    "p1 = np.poly1d(f1)\n",
    "\n",
    "f3 = np.polyfit(X, Y, 3)\n",
    "p3 = np.poly1d(f3)\n",
    "\n",
    "f5 = np.polyfit(X, Y, 5)\n",
    "p5 = np.poly1d(f5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131871a2-1f67-4fe1-bacd-40ba28922f2e",
   "metadata": {},
   "source": [
    "Plot the regression output against the actual data points to note how the data fits in each case. To plot the polynomial response over the actual data points, you have the function shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a00ad9-4644-4b19-9689-ef175e219d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(independent_variable.min(),independent_variable.max(),100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title(f'Polynomial Fit for Price ~ {Name}')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of laptops')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b42cb6-ad5b-4815-831a-6cf672b51ab5",
   "metadata": {},
   "source": [
    "Call this function for the 3 models created and get the required graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc9b3a-ecd2-4f04-962e-ae2498e89630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call for function of degree 1\n",
    "PlotPolly(p1, X, Y, 'CPU_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cd27a-67e8-4401-a0c9-ad9a4cea6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call for function of degree 3\n",
    "PlotPolly(p3, X, Y, 'CPU_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9338876-4ea7-41f4-b333-bc65e6fa1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call for function of degree 5\n",
    "PlotPolly(p5, X, Y, 'CPU_frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307b9ad-3e0c-4ae6-b845-4bd0045a1d47",
   "metadata": {},
   "source": [
    "calculate the R^2 and MSE values for these fits. For polynomial functions, the function sklearn.metrics.r2_score will be used to calculate R^2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1b956-73ff-4abc-b078-b11f86bc4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_1 = r2_score(Y, p1(X))\n",
    "print('The R-square value for 1st degree polynomial is: ', r_squared_1)\n",
    "print('The MSE value for 1st degree polynomial is: ', mean_squared_error(Y,p1(X)))\n",
    "r_squared_3 = r2_score(Y, p3(X))\n",
    "print('The R-square value for 3rd degree polynomial is: ', r_squared_3)\n",
    "print('The MSE value for 3rd degree polynomial is: ', mean_squared_error(Y,p3(X)))\n",
    "r_squared_5 = r2_score(Y, p5(X))\n",
    "print('The R-square value for 5th degree polynomial is: ', r_squared_5)\n",
    "print('The MSE value for 5th degree polynomial is: ', mean_squared_error(Y,p5(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f20a6-f5ee-4ca1-8109-da1ab89e482a",
   "metadata": {},
   "source": [
    "### 4.4 - Pipeline\n",
    "Create a pipeline that performs parameter scaling, Polynomial Feature generation and Linear regression. Use the set of multiple features as before to create this pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8821164-5a54-4f0e-9c45-518620f5e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]\n",
    "pipe=Pipeline(Input)\n",
    "Z = Z.astype(float)\n",
    "pipe.fit(Z,Y)\n",
    "ypipe=pipe.predict(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dac1c9-396c-4a7e-9443-681ef5815972",
   "metadata": {},
   "source": [
    "Evaluate the MSE and R^2 values for the this predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2466e-83a4-4d29-9d86-9259f2dd8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Write your code below and press Shift+Enter to execute\n",
    "print('MSE for multi-variable polynomial pipeline is: ', mean_squared_error(Y, ypipe))\n",
    "print('R^2 for multi-variable polynomial pipeline is: ', r2_score(Y, ypipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94797f-c650-4e47-820a-230ae478e7c4",
   "metadata": {},
   "source": [
    "You should now have seen that the values of R^2 increase as we go from Single Linear Regression to Multiple Linear Regression. Further, if we go for multiple linear regression extended with polynomial features, we get an even better R^2 value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6848f15-d210-457c-b72b-ced351fec13b",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation and Refinement\n",
    "\n",
    "- Use training, testing and cross validation to improve the performance of the dataset. \n",
    "- Identify the point of overfitting of a model\n",
    "- Use Ridge Regression to identify the change in performance of a model based on its hyperparameters\n",
    "- Use Grid Search to identify the best performing model using different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da7d50-287d-4365-91bf-514d2e227ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82496750-1e8c-4d0f-bdbc-08cd77208aa0",
   "metadata": {},
   "source": [
    "### 5.1 : Using Cross validation to improve the model\n",
    "\n",
    "Divide the dataset into x_data and y_data parameters. Here y_data is the \"Price\" attribute, and x_data has all other attributes in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af4d48-c12c-4191-bd73-db1f666c0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df['Price']\n",
    "x_data = df.drop('Price',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530dff6-2bbd-4a04-9440-1ca5a6301081",
   "metadata": {},
   "source": [
    "Split the data set into training and testing subests such that you reserve 10% of the data set for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c8e1c-b9c6-45fe-9893-ce7371fd1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)\n",
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91853d7d-4331-426c-ac36-b28894f32fcc",
   "metadata": {},
   "source": [
    "Create a single variable linear regression model using \"CPU_frequency\" parameter. Print the R^2 value of this model for the training and testing subsets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bf988-8873-496f-986b-16c2da787606",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre=LinearRegression()\n",
    "lre.fit(x_train[['CPU_frequency']], y_train)\n",
    "print(lre.score(x_test[['CPU_frequency']], y_test))\n",
    "print(lre.score(x_train[['CPU_frequency']], y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47ecf5-e029-419d-a5c5-c7d55c802667",
   "metadata": {},
   "source": [
    "Run a 4-fold cross validation on the model and print the mean value of R^2 score along with its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2caa02-e12b-43f5-bbf1-97f084224d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcross = cross_val_score(lre, x_data[['CPU_frequency']], y_data, cv=4)\n",
    "print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c0bdb-ff12-4e5f-b347-ed7590c9bac1",
   "metadata": {},
   "source": [
    "### 5.2: Overfitting\n",
    "\n",
    "Split the data set into training and testing components again, this time reserving 50% of the data set for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c39a4e-707f-4b0d-a80d-087d1b73e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.5, random_state=0)\n",
    "# fixing random_state to a fixed quantity helps maintain uniformity between multiple \n",
    "# executions of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336f4a0-3597-445f-bc5f-bca174a51a2c",
   "metadata": {},
   "source": [
    "To identify the point of overfitting the model on the parameter \"CPU_frequency\", you'll need to create polynomial features using the single attribute. You need to evaluate the R^2 scores of the model created using different degrees of polynomial features, ranging from 1 to 5. Save this set of values of R^2 score as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28f953-cad7-437c-ad4c-6dddd822fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = LinearRegression()\n",
    "Rsqu_test = []\n",
    "order = [1, 2, 3, 4, 5]\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    x_train_pr = pr.fit_transform(x_train[['CPU_frequency']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['CPU_frequency']])    \n",
    "    lre.fit(x_train_pr, y_train)\n",
    "    Rsqu_test.append(lre.score(x_test_pr, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382be4-87fc-4b60-a99d-89076e6b018d",
   "metadata": {},
   "source": [
    "Plot the values of R^2 scores against the order. Note the point where the score drops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142e10f-e326-4b79-bf2c-9d1f969e3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 Using Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bc232-127c-4f9c-9889-aff7087e51fc",
   "metadata": {},
   "source": [
    "### 5.3: Ridge Regression\n",
    "\n",
    "Now consider that you have multiple features, i.e. 'CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core','OS','GPU' and 'Category'. Create a polynomial feature model that uses all these parameters with degree=2. Also create the training and testing attribute sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed68a89-2c6a-4dc6-8da2-6b0a4676ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PolynomialFeatures(degree=2)\n",
    "x_train_pr=pr.fit_transform(x_train[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']])\n",
    "x_test_pr=pr.fit_transform(x_test[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c836d-435b-4523-91ce-4f72edd74311",
   "metadata": {},
   "source": [
    "Create a Ridge Regression model and evaluate it using values of the hyperparameter alpha ranging from 0.001 to 1 with increments of 0.001. Create a list of all Ridge Regression R^2 scores for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49cd35-9e23-4c62-9f62-fbde9ee4ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7eb974-f245-4b7c-836a-d14e1c8985f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsqu_test = []\n",
    "Rsqu_train = []\n",
    "Alpha = np.arange(0.001,1,0.001)\n",
    "pbar = tqdm(Alpha)\n",
    "\n",
    "for alpha in pbar:\n",
    "    RigeModel = Ridge(alpha=alpha) \n",
    "    RigeModel.fit(x_train_pr, y_train)\n",
    "    test_score, train_score = RigeModel.score(x_test_pr, y_test), RigeModel.score(x_train_pr, y_train)\n",
    "    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n",
    "    Rsqu_test.append(test_score)\n",
    "    Rsqu_train.append(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b8f17-d887-4e03-8589-de68f9940e9c",
   "metadata": {},
   "source": [
    "Plot the R^2 values for training and testing sets with respect to the value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6bb024-c79a-42dc-b382-8b65a8a9bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  \n",
    "plt.plot(Alpha, Rsqu_test, label='validation data')\n",
    "plt.plot(Alpha, Rsqu_train, 'r', label='training Data')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa5b81-0f81-4776-a0dc-ccfd5c57db7e",
   "metadata": {},
   "source": [
    "### 5.4: Grid Search\n",
    "\n",
    "Using the raw data and the same set of features as used above, use GridSearchCV to identify the value of alpha for which the model performs best. \n",
    "Assume the set of alpha values to be used as\n",
    "```math\n",
    "{0.0001, 0.001, 0.01, 0.1, 1, 10}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19066db4-df7f-4518-9d24-fadf0198ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1= [{'alpha': [0.0001,0.001,0.01, 0.1, 1, 10]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe8f56-18a4-4c67-83f2-ff505541c9aa",
   "metadata": {},
   "source": [
    "Create a Ridge instance and run Grid Search using a 4 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6b4db-5bb1-4474-887a-cac638bd657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR=Ridge()\n",
    "Grid1 = GridSearchCV(RR, parameters1,cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e01459-4655-46ee-8dd7-748cfaf5e796",
   "metadata": {},
   "source": [
    "Fit the Grid Search to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08455048-531f-401d-9ed5-b05c4bbfa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid1.fit(x_train[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a16df0-e209-4048-9bca-2a5d0f551d4a",
   "metadata": {},
   "source": [
    "Print the R^2 score for the test data using the estimator that uses the derived optimum value of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae10f07-f96a-417c-9afd-4a364cd6a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR=Grid1.best_estimator_\n",
    "print(BestRR.score(x_test[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core','OS','GPU','Category']], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45457deb-d332-467f-8dc3-d0f428e937b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
